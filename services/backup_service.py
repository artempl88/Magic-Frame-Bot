import os
import gzip
import asyncio
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Optional, Tuple
import logging
import shutil

from core.config import settings

logger = logging.getLogger(__name__)

class BackupService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±—ç–∫–∞–ø–∞–º–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self):
        self.backup_dir = Path("./backups")
        self.backup_dir.mkdir(exist_ok=True)
        
    async def create_backup(self, description: str = None) -> Tuple[bool, str, Optional[str]]:
        """
        –°–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        
        Returns:
            Tuple[bool, str, Optional[str]]: (success, message, file_path)
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"backup_{timestamp}.sql.gz"
            file_path = self.backup_dir / filename
            
            # –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–º–ø–∞ PostgreSQL
            pg_dump_cmd = [
                "docker", "exec", "-i", "client_postgres",
                "pg_dump", 
                "-U", settings.DB_USER,
                "-d", settings.DB_NAME,
                "--verbose",
                "--no-password"
            ]
            
            logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞: {filename}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º pg_dump –∏ —Å–∂–∏–º–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            process = await asyncio.create_subprocess_exec(
                *pg_dump_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                env={**os.environ, "PGPASSWORD": settings.DB_PASSWORD}
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode != 0:
                error_msg = stderr.decode() if stderr else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {error_msg}")
                return False, f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {error_msg}", None
            
            # –°–∂–∏–º–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            with gzip.open(file_path, 'wb') as f:
                f.write(stdout)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = file_path.stat().st_size
            size_mb = file_size / 1024 / 1024
            
            # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            await self._create_metadata(filename, description, file_size)
            
            success_msg = f"‚úÖ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ!\n" \
                         f"üìÅ –§–∞–π–ª: {filename}\n" \
                         f"üìä –†–∞–∑–º–µ—Ä: {size_mb:.1f} MB\n" \
                         f"üïê –í—Ä–µ–º—è: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}"
            
            if description:
                success_msg += f"\nüìù –û–ø–∏—Å–∞–Ω–∏–µ: {description}"
            
            logger.info(f"–ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {filename} ({size_mb:.1f} MB)")
            return True, success_msg, str(file_path)
            
        except Exception as e:
            error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –±—ç–∫–∞–ø–∞: {str(e)}"
            logger.error(error_msg, exc_info=True)
            return False, error_msg, None
    
    async def _create_metadata(self, filename: str, description: str, file_size: int):
        """–°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±—ç–∫–∞–ø–∞"""
        try:
            metadata_file = self.backup_dir / f"{filename}.meta"
            metadata = {
                "created_at": datetime.now().isoformat(),
                "description": description or "–†—É—á–Ω–æ–π –±—ç–∫–∞–ø",
                "size": file_size,
                "database": settings.DB_NAME,
                "user": settings.DB_USER
            }
            
            with open(metadata_file, 'w', encoding='utf-8') as f:
                import json
                json.dump(metadata, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {e}")
    
    async def list_backups(self) -> List[dict]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –±—ç–∫–∞–ø–æ–≤"""
        backups = []
        
        try:
            for backup_file in sorted(self.backup_dir.glob("backup_*.sql.gz"), reverse=True):
                metadata_file = backup_file.with_suffix(backup_file.suffix + ".meta")
                
                # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ
                stat = backup_file.stat()
                backup_info = {
                    "filename": backup_file.name,
                    "path": str(backup_file),
                    "size": stat.st_size,
                    "size_mb": stat.st_size / 1024 / 1024,
                    "created_at": datetime.fromtimestamp(stat.st_mtime),
                    "description": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –±—ç–∫–∞–ø"
                }
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                if metadata_file.exists():
                    try:
                        import json
                        with open(metadata_file, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                            backup_info.update({
                                "description": metadata.get("description", backup_info["description"]),
                                "created_at": datetime.fromisoformat(metadata.get("created_at", backup_info["created_at"].isoformat()))
                            })
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö {metadata_file}: {e}")
                
                backups.append(backup_info)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –±—ç–∫–∞–ø–æ–≤: {e}")
        
        return backups
    
    async def delete_backup(self, filename: str) -> Tuple[bool, str]:
        """–£–¥–∞–ª–∏—Ç—å –±—ç–∫–∞–ø"""
        try:
            backup_file = self.backup_dir / filename
            metadata_file = backup_file.with_suffix(backup_file.suffix + ".meta")
            
            if not backup_file.exists():
                return False, f"–§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω"
            
            # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –±—ç–∫–∞–ø–∞
            backup_file.unlink()
            
            # –£–¥–∞–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
            if metadata_file.exists():
                metadata_file.unlink()
            
            logger.info(f"–ë—ç–∫–∞–ø —É–¥–∞–ª–µ–Ω: {filename}")
            return True, f"‚úÖ –ë—ç–∫–∞–ø {filename} —É–¥–∞–ª–µ–Ω"
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –±—ç–∫–∞–ø–∞: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    async def cleanup_old_backups(self, days: int = 30) -> Tuple[int, str]:
        """–£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days)
            deleted_count = 0
            total_size = 0
            
            for backup_file in self.backup_dir.glob("backup_*.sql.gz"):
                file_time = datetime.fromtimestamp(backup_file.stat().st_mtime)
                
                if file_time < cutoff_date:
                    file_size = backup_file.stat().st_size
                    total_size += file_size
                    
                    # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    backup_file.unlink()
                    metadata_file = backup_file.with_suffix(backup_file.suffix + ".meta")
                    if metadata_file.exists():
                        metadata_file.unlink()
                    
                    deleted_count += 1
                    logger.info(f"–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –±—ç–∫–∞–ø: {backup_file.name}")
            
            size_mb = total_size / 1024 / 1024
            result_msg = f"üßπ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞:\n" \
                        f"üìÅ –£–¥–∞–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {deleted_count}\n" \
                        f"üíæ –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ –º–µ—Å—Ç–∞: {size_mb:.1f} MB"
            
            logger.info(f"–û—á–∏—Å—Ç–∫–∞ –±—ç–∫–∞–ø–æ–≤: —É–¥–∞–ª–µ–Ω–æ {deleted_count} —Ñ–∞–π–ª–æ–≤ ({size_mb:.1f} MB)")
            return deleted_count, result_msg
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –±—ç–∫–∞–ø–æ–≤: {str(e)}"
            logger.error(error_msg)
            return 0, error_msg
    
    async def get_backup_stats(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±—ç–∫–∞–ø–æ–≤"""
        try:
            backups = await self.list_backups()
            total_size = sum(b["size"] for b in backups)
            
            if backups:
                latest_backup = max(backups, key=lambda x: x["created_at"])
                oldest_backup = min(backups, key=lambda x: x["created_at"])
            else:
                latest_backup = oldest_backup = None
            
            return {
                "total_count": len(backups),
                "total_size": total_size,
                "total_size_mb": total_size / 1024 / 1024,
                "latest_backup": latest_backup,
                "oldest_backup": oldest_backup,
                "backup_dir": str(self.backup_dir.absolute())
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {
                "total_count": 0,
                "total_size": 0,
                "total_size_mb": 0,
                "latest_backup": None,
                "oldest_backup": None,
                "backup_dir": str(self.backup_dir.absolute())
            }
    
    async def restore_backup(self, filename: str) -> Tuple[bool, str]:
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±—ç–∫–∞–ø–∞
        ‚ö†Ô∏è –û–ü–ê–°–ù–ê–Ø –û–ü–ï–†–ê–¶–ò–Ø - –∑–∞–º–µ–Ω—è–µ—Ç –≤—Å—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö!
        """
        try:
            backup_file = self.backup_dir / filename
            
            if not backup_file.exists():
                return False, f"–§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω"
            
            logger.warning(f"–í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï –ë–î –∏–∑ {filename}")
            
            # –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
            drop_db_cmd = [
                "docker", "exec", "-i", "client_postgres",
                "dropdb", "-U", settings.DB_USER, settings.DB_NAME
            ]
            
            create_db_cmd = [
                "docker", "exec", "-i", "client_postgres", 
                "createdb", "-U", settings.DB_USER, settings.DB_NAME
            ]
            
            restore_cmd = [
                "docker", "exec", "-i", "client_postgres",
                "psql", "-U", settings.DB_USER, "-d", settings.DB_NAME
            ]
            
            # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ë–î
            process = await asyncio.create_subprocess_exec(
                *drop_db_cmd,
                env={**os.environ, "PGPASSWORD": settings.DB_PASSWORD}
            )
            await process.communicate()
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –ë–î  
            process = await asyncio.create_subprocess_exec(
                *create_db_cmd,
                env={**os.environ, "PGPASSWORD": settings.DB_PASSWORD}
            )
            await process.communicate()
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            with gzip.open(backup_file, 'rb') as f:
                process = await asyncio.create_subprocess_exec(
                    *restore_cmd,
                    stdin=asyncio.subprocess.PIPE,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE,
                    env={**os.environ, "PGPASSWORD": settings.DB_PASSWORD}
                )
                
                stdout, stderr = await process.communicate(input=f.read())
                
                if process.returncode != 0:
                    error_msg = stderr.decode() if stderr else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
                    logger.error(f"–û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {error_msg}")
                    return False, f"–û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {error_msg}"
            
            success_msg = f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ {filename}"
            logger.warning(f"–ë–î –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ {filename}")
            return True, success_msg
            
        except Exception as e:
            error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {str(e)}"
            logger.error(error_msg, exc_info=True)
            return False, error_msg

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
backup_service = BackupService() 